%--------1---------2---------3---------4---------5---------6---------7
%
% Competition paper
% SBST 2013
% Page limit: 4 pages
%

%\documentclass[10pt, conference, compsocconf]{IEEEtran}
\documentclass[10pt,conference,compsocconf]{IEEEtran}

%\documentclass[times, 10pt,twocolumn]{article} 
%\usepackage{latex8}
%\usepackage{times}
\usepackage{amsfonts}
\usepackage[latin1]{inputenc}
\usepackage[english]{babel}
\usepackage{listings}
\usepackage{algorithmic}
\usepackage{float}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{subfigure}
\usepackage{hyperref}
\usepackage{color}
\usepackage[usenames,dvipsnames,table]{xcolor}
\usepackage{soul}
\usepackage{xspace}
\usepackage{boxedminipage}
\usepackage{alltt}
\usepackage{multirow}
\usepackage{paralist}
\usepackage{amsmath}



\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\floatname{algorithm}{Algorithm}

\newtheorem{definition}{Definition}


 %krams hinter fontadjust ist neu
  \definecolor{lightgrey}{rgb}{0.90,0.90,0.90}
\lstset{escapeinside={(*}{*)}}
  \lstloadlanguages{java}
 \lstdefinelanguage{pseudocode}
  {morekeywords={if, else, initialize, return, for, each, in, global, new}
   }
  \lstset{
    tabsize=2,
    mathescape=true,
    escapeinside={(*}{*)},
    captionpos=t,
    framerule=0pt,
    backgroundcolor=\color{lightgrey},
    basicstyle=\footnotesize\ttfamily,
    keywordstyle=\footnotesize\bfseries,
    numbers=none,
    numberstyle=\tiny,
    numbersep=1pt,
    fontadjust,
    breaklines=true,
    breakatwhitespace=false
  }    
      

\hypersetup{
colorlinks=true,
urlcolor=rltblue,
linkcolor=rltred,
citecolor=rltgreen,
bookmarksnumbered=true,
pdftitle={EvoSuite at the SBST 2013 Tool Competition},
pdfauthor={Gordon Fraser and Andrea Arcuri},
pdfsubject={Test case generation},
pdfkeywords={Test case generation, unit testing, test
  oracles, assertions, search based testing}
}

\definecolor{rltred}{rgb}{0.5,0,0}
\definecolor{rltgreen}{rgb}{0,0.5,0}
\definecolor{rltblue}{rgb}{0,0,0.5}
\definecolor{ScarletRed}{rgb}{0.80,0.00,0.00}



% in draft mode we put \remarks into the margins and do other stuff
% set to \draftfalse for 
\newif\ifdraft
\draftfalse

\ifdraft
	\marginparwidth=1.3cm
	\marginparsep=5pt
	\newcommand\remark[1]{%
		\mymarginpar{\raggedright\hbadness=10000\tiny\it #1\par}}
\else
	\newcommand\remark[1]	{}
\fi

\ifdraft
	\overfullrule3pt
\fi    

% We use \FIXME for located problems (``defect'')
\newcommand{\FIXME}[1]{\remark{FIXME: #1}}
\newcommand\parremark[1]	{\par\textbf{REMARK:} #1\par}

\newcommand{\gordon}[1]{\textcolor{blue}{\sf\small\textbf{Gordon:} #1}}
\newcommand{\andrea}[1]{\textcolor{ScarletRed}{\sf\small\textbf{Andrea:} #1}}

% \mathid is used to denote identifiers and slots in formulas
\newcommand{\mathid}[1]{\text{\rmfamily\textit{#1}}}

% But usually, we shall use \|name| instead.
\def\|#1|{\mathid{#1}}

% \codeid is used to denote computer code identifiers
\newcommand{\codeid}[1]{\texttt{#1}}

% But usually, we shall use \<name> instead.
\def\<#1>{\codeid{#1}}

% Our results
\newenvironment{result}%
{\smallskip
\noindent
\let\emph=\textbf
\begin{boxedminipage}{\columnwidth}\begin{center}\em}%
{\end{center}\end{boxedminipage}%
\smallskip
}

\newcommand{\JodaTime}{Joda-Time\xspace}  % That's how they write themselves -- AZ

\newcommand{\EVOSUITE}{{\sc EvoSuite}\xspace}
\newcommand{\MUTEST}{{\sc $\mu$Test}\xspace}
\newcommand{\CS}{{\sc SF100}\xspace}

% TODO marker
\newcommand{\TODO}[1]{\sethlcolor{yellow}\textbf{\textcolor{ScarletRed}{\hl{TODO: #1}}}\xspace}


\DeclareMathSymbol{,}{\mathpunct}{letters}{"3B}
\DeclareMathSymbol{,}{\mathord}{letters}{"3B}
\DeclareMathSymbol{\decimal}{\mathord}{letters}{"3A}
%%%"

%\documentstyle[times,art10,twocolumn,latex8]{article}

%------------------------------------------------------------------------- 
% take the % away on next line to produce the final camera-ready version 
%\pagestyle{empty}

%------------------------------------------------------------------------- 
\begin{document}

%\title{Unit Testing Tool competition: Results for EvoSuite}
\title{EvoSuite at the SBST 2015 Tool Competition}

\author{
\IEEEauthorblockN{Gordon Fraser}
\IEEEauthorblockA{University of Sheffield\\
Sheffield, UK}\\
%gordon.fraser@sheffield.ac.uk}\\
\and
\IEEEauthorblockN{Andrea Arcuri}
\IEEEauthorblockA{Scienta, Norway\\
and University of Luxembourg}\\
%arcuri@simula.no}
%\and
%\IEEEauthorblockN{Jeremias R\"{o}{\ss}ler}
%\IEEEauthorblockA{Saarland University -- Computer Science\\
%Saarbr\"ucken, Germany\\
%roessler@cs.uni-saarland.de}
}

\maketitle
%\thispagestyle{empty}

\begin{abstract}
  \EVOSUITE is a mature research prototype that automatically
  generates unit tests for Java code.  This paper summarizes the
  results and experiences in participating at the third unit testing
  competition held at SBST 2015. An unfortunate issue of conflicting
  dependency versions in two out of the nine projects used in the
  benchmark reduced \EVOSUITE's overall score to $190.6$, and thus the
  second rank.
\end{abstract}

\begin{IEEEkeywords}
  test case generation; search-based testing; testing classes;
  search-based software engineering
\end{IEEEkeywords}


%------------------------------------------------------------------------- 
\section{Introduction}

This paper describes the results of applying the \EVOSUITE test
generation tool~\cite{FrA11c} to the benchmark used in the tool
competition at the International Workshop on Search-Based Software
Testing (SBST) 2015.  Details on the competition and the benchmark can
be found in~\cite{sbst2015}. In this competition, \EVOSUITE ranked
second with a score of $190.6$.

%------------------------------------------------------------------------- 
\section{About \EVOSUITE}


\begin{table}[!h]
\renewcommand{\arraystretch}{1.3}
\caption{Classification of the \EVOSUITE unit test generation tool.}\label{tool-description}
\begin{tabular}{|l|p{5cm}|}
  \hline
  \multicolumn{2}{|l|}{Prerequisites} \\
  \hline
  Static or dynamic &  Dynamic testing at the Java class level\\
  Software Type &  Java classes\\
  Lifecycle phase&  Unit testing for Java programs\\
  Environment&  All Java development environments \\
  Knowledge required & JUnit unit testing for Java\\
  Experience required &  Basic unit testing knowledge\\
 \hline
  \multicolumn{2}{|l|}{Input and Output of the tool} \\
  \hline
 Input & Bytecode of the target class and dependencies \\
\hline
Output&  JUnit test cases (version 3 or 4)\\
 
  \hline
  \multicolumn{2}{|l|}{Operation} \\
  \hline
  Interaction &  Through the command line, and Eclipse plugin\\
  User guidance &  manual verification of assertions for functional faults\\
  Source of information &  http://www.evosuite.org \\
  Maturity&  Mature research prototype, under development\\
  Technology behind the tool & Search-based testing / whole test suite generation\\
\hline
  \multicolumn{2}{|l|}{Obtaining the tool and information} \\
  \hline
License & GNU General Public License V3\\
Cost & Open source\\
Support & None \\
\hline
\hline
  \multicolumn{2}{|l|}{Does there exist empirical evidence about} \\
  \hline
  Effectiveness and Scalability & See~\cite{GoA_TSE12,fraser2014large}. \\
%Completeness & \\
%Effectiveness & \\
%Efficiency & \\
%Defect types & \\
%Scalability & \\
%Comprehensibility & \\
%Learnability & \\
%Subjective satisfaction & \\
%Other & \\
\hline
\end{tabular}\vspace{-1em}
\end{table}


\EVOSUITE~\cite{FrA11c,GoA_TSE12} automatically generates test suites
for Java classes, targeting branch coverage and other coverage
criteria (e.g., mutation testing~\cite{emse14_mutation}). \EVOSUITE
works at the Java bytecode level, i.e., it does not require source
code. It is fully automated and requires no manually written test
drivers or parameterized unit tests.  For example, when \EVOSUITE is
used from its Eclipse plugin, a user
just needs to select a class, and tests are generated with a mouse-click.

\EVOSUITE has been evaluated on millions of lines of Java
code~\cite{fraser2014large}, both open-source code and close-source
code provided by one of our industrial partners.  In the previous two
editions of the unit testing tool competition, \EVOSUITE ranked
first~\cite{evosuiteAtSbst2013,evosuiteAtFittest2013}.


\EVOSUITE uses an evolutionary approach to derive these test suites: A
genetic algorithm evolves candidate individuals (chromosomes) using
operators inspired by natural evolution (e.g., selection, crossover
and mutation), such that iteratively better solutions with respect to
the optimization target (e.g., branch coverage) are produced.  For
details on this test generation approach we refer to~\cite{GoA_TSE12}.
To improve performance further, we are investigating several
extensions to \EVOSUITE. 
For example, \EVOSUITE can employ dynamic
symbolic execution~\cite{evoISSRE113} 
and memetic algorithms~\cite{fraser2014memetic}
to handle the cases in which our genetic algorithm may struggle. 


As the generated unit tests are meant for human
consumption~\cite{fraser2013does}, \EVOSUITE applies various
post-processing steps to improve readability (e.g., minimising) and
adds test assertions that capture the current behavior of the tested
classes. To select the most effective assertions, \EVOSUITE uses
mutation analysis~\cite{10.1109/TSE.2011.93}.  \EVOSUITE can also be
used to automatically find faults in the CUTs~\cite{emse13_oracle},
e.g., undeclared thrown exceptions and broken code contracts.  For
more details on the tool and its abilities we refer to~\cite{FrA11c},
and for more implementation details we refer to~\cite{FrA13a}.

%------------------------------------------------------------------------- 
\section{Competition Setup}

We configured \EVOSUITE to use a dynamic timeout of maximum 10 minutes
for the search, with an earlier stop if the fitness value did not
increase for two minutes. The fitness function to drive the genetic
algorithm was based on a combination of line coverage, branch
coverage, and weak mutation testing. We enabled the post-processing
step of test minimization, but to reduce the time spent we included
all assertions rather than filtering them with mutation
analysis~\cite{10.1109/TSE.2011.93}. In practice, this may not result
in the most readable or maintainable test cases, but neither of these
two attributes is measured by the SBST contest metric.

%------------------------------------------------------------------------- 
\section{Benchmark results}

\begin{table*}[t]
  \centering
  \caption{\label{table:results}Detailed results of \EVOSUITE on the SBST benchmark classes. Time is expressed in minutes.}
  %\scriptsize
\resizebox{0.9\textwidth}{!}{  
  \begin{tabular}{l rrrrrr} \toprule
Class &  JUnit Files &   Generation Time & Execution Time   & \% Line Coverage & \% Branch Coverage & \% Mutation Score \\  
% Class & Generation Time & Execution Time  & Tests & Line Coverage & Branch Coverage & Mutation Score \\ 
%Class & \multicolumn{2}{c}{ Time} & Tests & Line Coverage & Branch
%Coverage & Mutation Score \\ 
%& Generation & Execution & & & & \\
\midrule
\input{results.tex}
\midrule
Average & & 6.19 & 0.03 & 55.36 & 47.19 & 41.02\\
\bottomrule
  \end{tabular}
}
\end{table*}

%average per class generation time:                 371.581857 seconds
%average per class execution time:                  2.103966 seconds
%average per class instruction coverage:            54.495767 %
%average per class line coverage:                   55.368111 %
%average per class branch coverage:                 47.192896 %
%average per class method coverage:                 59.628209 %
%average per class mutation coverage:               41.024248 %

The results of \EVOSUITE on the benchmark classes are listed in
Table~\ref{table:results}. On average, \EVOSUITE achieved TODO line
coverage,TODO branch coverage\footnote{Using Cobertura's definition
  of branch coverage, which only counts conditional statements, not
  edges in the CFG.}, and TODO mutation score. On average, \EVOSUITE
produced TODO tests per class, and it took an average of TODO per class to
do so.
% (with \EVOSUITE configured to 3 minutes per class).



\subsection{Issues Encountered}

% CharMatcher: Timeout
% CycleHandler, WikipediaInfo: Infinite loop in generic resolving
% Response requires java.net.HttpURLConnection

Out of 63 CUTs, \EVOSUITE did not manage to obtain any coverage for 18
classes, i.e., 28\% of all classes.  For 14 of them (the 7 in the
twitter4j and the 7 in the hibernate projects), this is due to a
mismatch in libraries on the classpath.  In particular, \EVOSUITE does
bytecode instrumentation using the ASM library.  However, the projects
of the CUTs had their own (older) version of ASM.  This leads to
errors like: ``java.lang.IncompatibleClassChangeError: class
org.objectweb.asm.tree.ClassNode has interface
org.objectweb.asm.ClassVisitor as super class''.  Note: \EVOSUITE can
handle its own dependencies as CUTs, i.e., by using customized
classloaders, but only during the search phase.  In the generated
JUnit files, those have dependencies to ASM, as we do bytecode
instrumentation even there (e.g., to support environment testing based
on mock objects~\cite{arcuri2014automated}).  So, \EVOSUITE does
generate tests for those 14 classes, but then all those tests fails
due to that thrown exception.  An easy solution would be to ship
\EVOSUITE with its own ASM version using a different package name
(e.g., by using the JarJar
tool\footnote{https://code.google.com/p/jarjar/}).
%
If we had handled this issue properly before the competition, this
would have changed the result: Excluding classes from the twitter4j
and hibernate, the overall score of \EVOSUITE would be 191.584,
whereas GRT would have a score of 164.464. Consequently, this issue
clearly is the main factor affecting \EVOSUITE's overall result.

For the other four classes with 0\% coverage, \EVOSUITE failed to
generate any tests. For \<CharMatcher>, the issue is an issue in how
\EVOSUITE handled timeouts, which resulted in \EVOSUITE's master
process killing the client process before tests were written to
disk. For \<CycleHandler> and \<WikipediaInfo>, \EVOSUITE ran into an
issue when trying to resolve the generic type parameters of some
dependency classes. This issue could be avoided by omitting generic
type parameters, as the Java compiler would only issue warnings about
such missing parameters. However, as \EVOSUITE is aiming to produce
readable tests, we feel it is important to properly handle Java
Generics. Finally, for \<Response> the constructor requires a
parameter of type \<java.net.HttpURLConnection>, which is an abstract
class without concrete subclasses. As \EVOSUITE does not produce stubs
automatically, it therefore failed to instantiate \<Response> objects.

There are also a further 4 cases of low coverage (e.g., less than
30\%).  For example, if look at line coverage, then we have \<Page>
with 1.49\%, \<AbstractInstance> with 13.28\%,
\<CategoryDescendantsIterator> with 8.24\% and \<PageQueryIterable>
with 18.57\%.  

TODO: Will look into these four.

%To improve \EVOSUITE, it will be important to
%understand why that was the case.


%------------------------------------------------------------------------- 
\section{Conclusions}

With an overall score of $190.6$, \EVOSUITE achieved the second
highest score of all tools in the competition. The score calculated
for the best tool is $203.7$: a very close call.  In particular, if
considering only projects without a configuration issue in the
classpath of the target projects, \EVOSUITE would have scored first
with a score of $191.6$.
%
%due to
%a configuration issue in the classpath of the target projects,
%\EVOSUITE could had been run only on 7 out of 9 of the projects used
%as benchmark.  
The underlying issue can be easily fixed for future runs of the
competition.
% issue that would lead to even
%higher scores.


To learn more about \EVOSUITE, visit our Web site:
\begin{center}
%\url{http://evosuite.org/}
\texttt{http://www.evosuite.org}
\end{center}


%------------------------------------------------------------------------- 

%\noindent
%\textbf{Acknowledgments.} 



%------------------------------------------------------------------------- 
%\def\IEEEbibitemsep{5pt plus 1pt}
\def\IEEEbibitemsep{6pt}

\bibliographystyle{IEEEtranS}
\bibliography{papers}

\end{document}

