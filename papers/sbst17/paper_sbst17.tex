%--------1---------2---------3---------4---------5---------6---------7
%
% Competition paper
% SBST 2013
% Page limit: 4 pages
%

%\documentclass[10pt, conference, compsocconf]{IEEEtran}
%\documentclass[10pt,conference,compsocconf]{IEEEtran}
\documentclass[10pt,conference]{IEEEtran} 


%\documentclass[times, 10pt,twocolumn]{article} 
%\usepackage{latex8}
%\usepackage{times}
\usepackage{amsfonts}
\usepackage[latin1]{inputenc}
\usepackage[english]{babel}
\usepackage{listings}
\usepackage{algorithmic}
\usepackage{float}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{subfigure}
%\usepackage{hyperref}
\usepackage{color}
\usepackage[usenames,dvipsnames,table]{xcolor}
%\usepackage{soul}
\usepackage{xspace}
\usepackage{boxedminipage}
\usepackage{alltt}
\usepackage{multirow}
\usepackage{paralist}
\usepackage{amsmath}
\usepackage{balance}


\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\floatname{algorithm}{Algorithm}

\newtheorem{definition}{Definition}


 %krams hinter fontadjust ist neu
  \definecolor{lightgrey}{rgb}{0.90,0.90,0.90}
\lstset{escapeinside={(*}{*)}}
  \lstloadlanguages{java}
 \lstdefinelanguage{pseudocode}
  {morekeywords={if, else, initialize, return, for, each, in, global, new}
   }
  \lstset{
    tabsize=2,
    mathescape=true,
    escapeinside={(*}{*)},
    captionpos=t,
    framerule=0pt,
    backgroundcolor=\color{lightgrey},
    basicstyle=\scriptsize\ttfamily,
    keywordstyle=\footnotesize\bfseries,
    numbers=none,
    numberstyle=\tiny,
    numbersep=1pt,
    fontadjust,
    breaklines=true,
    breakatwhitespace=false
  }    
      

% \hypersetup{
% colorlinks=true,
% urlcolor=rltblue,
% linkcolor=rltred,
% citecolor=rltgreen,
% bookmarksnumbered=true,
% pdftitle={EvoSuite at the SBST 2016 Tool Competition},
% pdfauthor={Gordon Fraser and Andrea Arcuri},
% pdfsubject={Test case generation},
% pdfkeywords={Test case generation, unit testing, test
%   oracles, assertions, search based testing}
% }

\definecolor{rltred}{rgb}{0.5,0,0}
\definecolor{rltgreen}{rgb}{0,0.5,0}
\definecolor{rltblue}{rgb}{0,0,0.5}
\definecolor{ScarletRed}{rgb}{0.80,0.00,0.00}



% in draft mode we put \remarks into the margins and do other stuff
% set to \draftfalse for 
\newif\ifdraft
\draftfalse

\ifdraft
	\marginparwidth=1.3cm
	\marginparsep=5pt
	\newcommand\remark[1]{%
		\mymarginpar{\raggedright\hbadness=10000\tiny\it #1\par}}
\else
	\newcommand\remark[1]	{}
\fi

\ifdraft
	\overfullrule3pt
\fi    

% We use \FIXME for located problems (``defect'')
\newcommand{\FIXME}[1]{\remark{FIXME: #1}}
\newcommand\parremark[1]	{\par\textbf{REMARK:} #1\par}

\newcommand{\gordon}[1]{\textcolor{blue}{\sf\small\textbf{Gordon:} #1}}
\newcommand{\andrea}[1]{\textcolor{ScarletRed}{\sf\small\textbf{Andrea:} #1}}

% \mathid is used to denote identifiers and slots in formulas
\newcommand{\mathid}[1]{\text{\rmfamily\textit{#1}}}

% But usually, we shall use \|name| instead.
\def\|#1|{\mathid{#1}}

% \codeid is used to denote computer code identifiers
\newcommand{\codeid}[1]{\texttt{#1}}

% But usually, we shall use \<name> instead.
\def\<#1>{\codeid{#1}}

% Our results
\newenvironment{result}%
{\smallskip
\noindent
\let\emph=\textbf
\begin{boxedminipage}{\columnwidth}\begin{center}\em}%
{\end{center}\end{boxedminipage}%
\smallskip
}

\newcommand{\JodaTime}{Joda-Time\xspace}  % That's how they write themselves -- AZ

\newcommand{\EVOSUITE}{{\sc EvoSuite}\xspace}
\newcommand{\MUTEST}{{\sc $\mu$Test}\xspace}
\newcommand{\CS}{{\sc SF100}\xspace}

% TODO marker
\newcommand{\TODO}[1]{\sethlcolor{yellow}\textbf{\textcolor{ScarletRed}{\hl{TODO: #1}}}\xspace}


\DeclareMathSymbol{,}{\mathpunct}{letters}{"3B}
\DeclareMathSymbol{,}{\mathord}{letters}{"3B}
\DeclareMathSymbol{\decimal}{\mathord}{letters}{"3A}
%%%"

%\documentstyle[times,art10,twocolumn,latex8]{article}



%------------------------------------------------------------------------- 
% take the % away on next line to produce the final camera-ready version 
%\pagestyle{empty}

%------------------------------------------------------------------------- 
\begin{document}

% 

%\title{Unit Testing Tool competition: Results for EvoSuite}
\title{EvoSuite at the SBST 2017 Tool Competition}
 

\author{\IEEEauthorblockN{Authors}}


\maketitle
%\thispagestyle{empty}

\begin{abstract}
  \EVOSUITE is a search-based tool that automatically generates unit
  tests for Java code.  This paper summarizes the results and
  experiences of \EVOSUITE's participation at the fifth unit testing
  competition at SBST 2017, where \EVOSUITE achieved the highest
  overall score.
\end{abstract}



%------------------------------------------------------------------------- 
\section{Introduction}
The annual unit test generation competition aims to drive and evaluate
progress on unit test generation tools. In the 5th instance of the
competition at the International Workshop on Search-Based Software
Testing (SBST) 2017, four tools competed on a set of open source Java
classes. This paper describes the results of applying the \EVOSUITE
test generation tool~\cite{FrA11c} in this competition. Details about
the procedure of the competition, the technical framework, and the
benchmark classes can be found in~\cite{sbst17competition}.  In this
competition, \EVOSUITE achieved a 1457.3 overall score, which was the
highest among the competing tools.

%------------------------------------------------------------------------- 
\section{About EvoSuite}


\begin{table}[!h]
\renewcommand{\arraystretch}{1.3}
\caption{Classification of the \EVOSUITE unit test generation
  tool.}\label{tool-description}
\resizebox{1.0\columnwidth}{!}{  
\begin{tabular}{|l|p{5cm}|}
  \hline
  \multicolumn{2}{|l|}{Prerequisites} \\
  \hline
  Static or dynamic &  Dynamic testing at the Java class level\\
  Software Type &  Java classes\\
  Lifecycle phase&  Unit testing for Java programs\\
  Environment&  All Java development environments \\
  Knowledge required & JUnit unit testing for Java\\
  Experience required &  Basic unit testing knowledge\\
 \hline
  \multicolumn{2}{|l|}{Input and Output of the tool} \\
  \hline
 Input & Bytecode of the target class and dependencies \\
\hline
Output&  JUnit 4 test cases\\
 
  \hline
  \multicolumn{2}{|l|}{Operation} \\
  \hline
  Interaction &  Through the command line, and plugins for IntelliJ, Maven and Eclipse\\
  User guidance &  manual verification of assertions for functional faults\\
  Source of information &  http://www.evosuite.org \\
  Maturity&  Mature research prototype, under development\\
  Technology behind the tool & Search-based testing / whole test suite generation\\
\hline
  \multicolumn{2}{|l|}{Obtaining the tool and information} \\
  \hline
License & Lesser GPL V.3\\
Cost & Open source\\
Support & None \\
\hline
\hline
  \multicolumn{2}{|l|}{Does there exist empirical evidence about} \\
  \hline
  Effectiveness and Scalability & See~\cite{GoA_TSE12,fraser2014large}. \\
%Completeness & \\
%Effectiveness & \\
%Efficiency & \\
%Defect types & \\
%Scalability & \\
%Comprehensibility & \\
%Learnability & \\
%Subjective satisfaction & \\
%Other & \\
\hline
\end{tabular}\vspace{-1em}
}
\end{table}


\EVOSUITE~\cite{FrA11c} is a search-based tool~\cite{GoA_TSE12} that
uses a genetic algorithm to automatically generate test suites for
Java classes. Given the name of a target class and the full Java
classpath (i.e., where to find the compiled bytecode of the class
under test and all its dependencies), \EVOSUITE automatically produces
a set of JUnit test cases that maximise the achieved code
coverage. \EVOSUITE can be used on the command line, or through
plugins for popular development tools such as IntelliJ, Eclipse, or Maven~\cite{ICST16_Tool}.

The underlying genetic algorithm uses test suites as representation
(chromosomes). Each test suite consists of a variable number of test
cases, each of which is represented as a variable length sequence of
Java statements (e.g., calls on the class under test). A population of
randomly generated individuals is evolved using suitable search
operators (e.g., selection, crossover and mutation), such that
iteratively better solutions with respect to the optimisation target
are produced. The optimisation target is to maximise code coverage. To
achieve this, the fitness function uses standard heuristics such as
the branch distance; see~\cite{GoA_TSE12} for more details. \EVOSUITE
can be configured to optimise for multiple coverage criteria at the
same time, and the default configuration combines branch coverage with
mutation testing~\cite{emse14_mutation} and other basic
criteria~\cite{rojas2015combining}. Once the search is completed,
\EVOSUITE applies various optimisations to improve the readability of
the generated tests. For example, tests are minimised, and a
minimised set of effective test assertions is selected using mutation
analysis~\cite{10.1109/TSE.2011.93}. For more details on the tool and
its abilities we refer to~\cite{FrA11c,FrA13a}.


The effectiveness of \EVOSUITE has been evaluated on open source as
well as industrial software in terms of code
coverage~\cite{fraser2014large,emse_archive}, fault finding
effectiveness~\cite{shamshiri2015automatically,moein2017}, and effects
on developer productivity~\cite{TOSEM_userstudy,ISSTA15_Study}.

In the first two and the fourth editions of the unit testing tool
competition, \EVOSUITE ranked
first~\cite{evosuiteAtSbst2013,evosuiteAtFittest2013,evosuiteAtSbst2016},
whereas it ranked second in the third one.






%To improve performance further, we are investigating several
%extensions to \EVOSUITE. 
%For example, \EVOSUITE can employ dynamic
%symbolic execution~\cite{evoISSRE113} 
%and memetic algorithms~\cite{fraser2014memetic}
%to handle the cases in which our genetic algorithm may struggle. 


%------------------------------------------------------------------------- 
\section{Competition Setup}

The configuration of \EVOSUITE for the competition is largely based on
its default values, since these have been tuned
extensively~\cite{arcuri2013parameter}. We used the default set of
coverage criteria~\cite{rojas2015combining} (e.g., line coverage,
branch coverage, branch coverage by direct method invocation, weak
mutation testing, output coverage, exception coverage). The use of an
archive of solutions~\cite{emse_archive}, which iteratively removes
covered goals from the fitness function and stores the corresponding
test cases is now enabled by default in \EVOSUITE.

A new feature in \EVOSUITE is the use of Mockito mock
classes~\cite{ICST_Mocking17}. After a certain percentage of the
search budget has passed, \EVOSUITE starts considering the use of mock
objects instead of real classes. Only branches that cannot be covered
without mocks will result in tests with mock objects in the end. We
further added frequency based weighting to constants for
seeding~\cite{sakti2015instance}, and included extensions to support
Java Enterprise Edition features~\cite{arcuri2016java}. Besides these
changes, several bug fixes were applied since the last instance of the
competition, in particular in relation to non-determinism and flaky
tests~\cite{ase14_environment}.

Like in previous instances of the competition, we enabled the
post-processing step of test minimisation (but not for efficiency
reasons, but because minimised tests are less likely to break). To
reduce the overall time of test generation we included all assertions
rather than filtering them with mutation
analysis~\cite{10.1109/TSE.2011.93}, which is a computationally
expensive process. The use of all assertions has a negative impact on
readability, but this is not evaluated as part of the SBST contest.

Like in the 2016 competition, tools were called with different time
budgets. We used the same strategy as for the previous
competition~\cite{evosuiteAtSbst2016} to distribute the overall time
budget onto the different phases of \EVOSUITE (e.g., initialization,
search, minimization, assertion generation, compilation check, removal
of flaky tests). That is, 50\% of the time was allocated to the
search, and the rest was distributed equally to the remaining
phases.


%------------------------------------------------------------------------- 
\section{Benchmark results}

% \begin{table*}[t]
%   \centering
%   \caption{\label{table:results}Detailed results of \EVOSUITE on the SBST benchmark classes.}
% \resizebox{0.9\textwidth}{!}{  
% \input{mainTable.tex}
% }	
% \end{table*}

\begin{table*}[t]
  \centering
  \caption{\label{table:coverage_results}Detailed coverage results of \EVOSUITE on the SBST benchmark classes.}
\resizebox{0.8\textwidth}{!}{  
%\input{coverageTable.tex}
}
\end{table*}

\begin{table*}[t]
  \centering
  \caption{\label{table:fault_results}Detailed fault detection results of \EVOSUITE on the SBST benchmark classes.}
\resizebox{0.8\textwidth}{!}{  
%\input{faultTable.tex}
}	
\end{table*}



The coverage results (line coverage and branch coverage) achieved by
\EVOSUITE on the benchmark classes are listed in
Table~\ref{table:coverage_results}. Coverage is generally in the
expected range, with clear increases for higher time budgets. Coverage
on several of the benchmarks from Closure is low, which matches
previous findings~\cite{shamshiri2015automatically}. 

Results in terms of mutation scores and fault detection ratio (i.e.,
how many of the runs had at least one failing test on the
corresponding bug) are showing in
Table~\ref{table:fault_results}. Again the Closure results are
generally worse than those of other projects, both in terms of
mutation score and ratio of fault detection.

On average, \EVOSUITE generated 0.14 flaky tests per run, a value that
is significantly lower than that of any of the competing tools. This
is due to extensive efforts to isolate \EVOSUITE tests from the
execution environment~\cite{arcuri2014automated}. A few of these flaky
tests were introduced by recent changes to \EVOSUITE following
experiments on Defects4J~\cite{shamshiri2015automatically}: \EVOSUITE
now includes assertions on the source of exceptions, similar to
commercial tools like Agitar One. %~\cite{agitarone}. 
Unfortunately, there were several instances in the competition where these assertions
lead to flaky tests. For example, the following is an excerpt from a
test for the Defects4J bug Lang-41, generated by \EVOSUITE:
\vspace{1em}

\begin{lstlisting}
@Test(timeout = 4000)
public void test19()  throws Throwable  {
 Class<Double> class0 = Double.class;
 String string0 = ClassUtils.getPackageName(class0);
 try { 
   ClassUtils.getClass(string0);
   fail("Expecting exception: ClassNotFoundException"); 
 } catch(ClassNotFoundException e) {
   assertThrownBy("java.net.URLClassLoader", e);
 }
}
\end{lstlisting}

While compiling and executing this test with JUnit works without
problems, the mutation analysis step of the competition used Ant to
run the tests; Ant uses a complex setup of classloaders that
eventually leads to the \texttt{assertThrownBy} in the above example
to fail, as the source of the exception is a different one.

There are 15 runs in total where \EVOSUITE did not produce any test
suites; these are only for higher time budgets (240s, 480s). The
majority of these runs are due to \EVOSUITE not terminating before the
hard timeout of the competition infrastructure. This may happen, for
example, when test execution on the class under test takes long (e.g.,
timeouts), and when resetting the static state of the classes under
test takes a long time. However, this number is still lower than the
number of erroneous runs compared to other tools, and in the remaining
1617 runs of the competition \EVOSUITE terminated in time and produced
at least two tests. In 13 of these, \EVOSUITE produced a test suite
with a compilation error.

%------------------------------------------------------------------------- 
\section{Conclusions}

With an overall score of 1126.7, \EVOSUITE achieved the highest score
of all tools in the competition. 


To learn more about \EVOSUITE, visit our Web site:
\begin{center}
%\url{http://evosuite.org/}
\texttt{http://www.evosuite.org}
\end{center}


%------------------------------------------------------------------------- 

%\noindent
\textbf{Acknowledgments:} Many thanks to all the contributors to \EVOSUITE.
This project has been funded by 
%the EPSRC project ``EXOGEN'' (EP/K030353/1), a Google Focused Research Award on ``Test
%Amplification'', and by 
the National Research Fund, Luxembourg (FNR/P10/03).


%------------------------------------------------------------------------- 
%\def\IEEEbibitemsep{5pt plus 1pt}
%\def\IEEEbibitemsep{6pt}

\bibliographystyle{IEEEtranS}
\bibliography{papers}
\balance

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
