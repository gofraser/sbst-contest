%--------1---------2---------3---------4---------5---------6---------7
%
% Competition paper
% SBST 2013
% Page limit: 4 pages
%

%\documentclass[10pt, conference, compsocconf]{IEEEtran}
\documentclass[10pt,conference,compsocconf]{IEEEtran}

%\documentclass[times, 10pt,twocolumn]{article} 
%\usepackage{latex8}
%\usepackage{times}
\usepackage{amsfonts}
\usepackage[latin1]{inputenc}
\usepackage[english]{babel}
\usepackage{listings}
\usepackage{algorithmic}
\usepackage{float}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{subfigure}
\usepackage{hyperref}
\usepackage{color}
\usepackage[usenames,dvipsnames,table]{xcolor}
\usepackage{soul}
\usepackage{xspace}
\usepackage{boxedminipage}
\usepackage{alltt}
\usepackage{multirow}
\usepackage{paralist}
\usepackage{amsmath}



\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\floatname{algorithm}{Algorithm}

\newtheorem{definition}{Definition}


 %krams hinter fontadjust ist neu
  \definecolor{lightgrey}{rgb}{0.90,0.90,0.90}
\lstset{escapeinside={(*}{*)}}
  \lstloadlanguages{java}
 \lstdefinelanguage{pseudocode}
  {morekeywords={if, else, initialize, return, for, each, in, global, new}
   }
  \lstset{
    tabsize=2,
    mathescape=true,
    escapeinside={(*}{*)},
    captionpos=t,
    framerule=0pt,
    backgroundcolor=\color{lightgrey},
    basicstyle=\footnotesize\ttfamily,
    keywordstyle=\footnotesize\bfseries,
    numbers=none,
    numberstyle=\tiny,
    numbersep=1pt,
    fontadjust,
    breaklines=true,
    breakatwhitespace=false
  }    
      
\def\svn$I#1: #2 #3 #4 #5 #6 ${\def\svnrev{#3}\def\svndate{#4}\def\svndoc{#2}}
\svn$Id: icst11.tex 21983 2011-01-07 16:22:58Z fraser $

\hypersetup{
colorlinks=true,
urlcolor=rltblue,
linkcolor=rltred,
citecolor=rltgreen,
bookmarksnumbered=true,
pdftitle={EvoSuite at the SBST 2013 Tool Competition},
pdfauthor={Gordon Fraser and Andrea Arcuri},
pdfsubject={Test case generation},
pdfkeywords={Test case generation, unit testing, test
  oracles, assertions, search based testing}
}

\definecolor{rltred}{rgb}{0.5,0,0}
\definecolor{rltgreen}{rgb}{0,0.5,0}
\definecolor{rltblue}{rgb}{0,0,0.5}
\definecolor{ScarletRed}{rgb}{0.80,0.00,0.00}



% in draft mode we put \remarks into the margins and do other stuff
% set to \draftfalse for 
\newif\ifdraft
\draftfalse

\ifdraft
	\marginparwidth=1.3cm
	\marginparsep=5pt
	\newcommand\remark[1]{%
		\mymarginpar{\raggedright\hbadness=10000\tiny\it #1\par}}
\else
	\newcommand\remark[1]	{}
\fi

\ifdraft
	\overfullrule3pt
\fi    

% We use \FIXME for located problems (``defect'')
\newcommand{\FIXME}[1]{\remark{FIXME: #1}}
\newcommand\parremark[1]	{\par\textbf{REMARK:} #1\par}

\newcommand{\gordon}[1]{\textcolor{blue}{\sf\small\textbf{Gordon:} #1}}
\newcommand{\andrea}[1]{\textcolor{ScarletRed}{\sf\small\textbf{Andrea:} #1}}

% \mathid is used to denote identifiers and slots in formulas
\newcommand{\mathid}[1]{\text{\rmfamily\textit{#1}}}

% But usually, we shall use \|name| instead.
\def\|#1|{\mathid{#1}}

% \codeid is used to denote computer code identifiers
\newcommand{\codeid}[1]{\texttt{#1}}

% But usually, we shall use \<name> instead.
\def\<#1>{\codeid{#1}}

% Our results
\newenvironment{result}%
{\smallskip
\noindent
\let\emph=\textbf
\begin{boxedminipage}{\columnwidth}\begin{center}\em}%
{\end{center}\end{boxedminipage}%
\smallskip
}

\newcommand{\JodaTime}{Joda-Time\xspace}  % That's how they write themselves -- AZ

\newcommand{\EVOSUITE}{{\sc EvoSuite}\xspace}
\newcommand{\MUTEST}{{\sc $\mu$Test}\xspace}
\newcommand{\CS}{{\sc SF100}\xspace}

% TODO marker
\newcommand{\TODO}[1]{\sethlcolor{yellow}\textbf{\textcolor{ScarletRed}{\hl{TODO: #1}}}\xspace}


\DeclareMathSymbol{,}{\mathpunct}{letters}{"3B}
\DeclareMathSymbol{,}{\mathord}{letters}{"3B}
\DeclareMathSymbol{\decimal}{\mathord}{letters}{"3A}
%%%"

%\documentstyle[times,art10,twocolumn,latex8]{article}

%------------------------------------------------------------------------- 
% take the % away on next line to produce the final camera-ready version 
%\pagestyle{empty}

%------------------------------------------------------------------------- 
\begin{document}

%\title{Unit Testing Tool competition: Results for EvoSuite}
\title{EvoSuite at the SBST 2013 Tool Competition}

\author{
\IEEEauthorblockN{Gordon Fraser}
\IEEEauthorblockA{University of Sheffield\\
Sheffield, UK\\
gordon.fraser@sheffield.ac.uk}\\
\and
\IEEEauthorblockN{Andrea Arcuri}
\IEEEauthorblockA{Certus Software V\&V Center at Simula Research Laboratory\\
P.O. Box 134, 1325 Lysaker, Norway\\
arcuri@simula.no}
%\and
%\IEEEauthorblockN{Jeremias R\"{o}{\ss}ler}
%\IEEEauthorblockA{Saarland University -- Computer Science\\
%Saarbr\"ucken, Germany\\
%roessler@cs.uni-saarland.de}
}

\maketitle
%\thispagestyle{empty}

\begin{abstract}
  \EVOSUITE is a mature research prototype that automatically
  generates unit tests for Java code.  This paper summarizes the
  results and experiences in participating at the unit testing
  competition held at SBST 2013, where \EVOSUITE ranked first with a
  score of $156.95$.
\end{abstract}

\begin{IEEEkeywords}
  test case generation; search-based testing; testing classes;
  search-based software engineering
\end{IEEEkeywords}


%------------------------------------------------------------------------- 
\section{Introduction}

This paper describes the results of applying the \EVOSUITE test
generation tool~\cite{FrA11c} to the benchmark used in the tool
competition at the International Workshop on Search-Based Software
Testing (SBST) 2013.  Details on the competition and the benchmark can
be found in~\cite{sbst2013}. In this competition, \EVOSUITE ranked
first with a score of $156.95$.

%------------------------------------------------------------------------- 
\section{About \EVOSUITE}


\begin{table}[!h]
\renewcommand{\arraystretch}{1.3}
\caption{Classification of the \EVOSUITE unit test generation tool.}\label{tool-description}
\begin{tabular}{|l|p{5cm}|}
  \hline
  \multicolumn{2}{|l|}{Prerequisites} \\
  \hline
  Static or dynamic &  Dynamic testing at the Java class level\\
  Software Type &  Java classes\\
  Lifecycle phase&  Unit testing for Java programs\\
  Environment&  All Java development environments \\
  Knowledge required & JUnit unit testing for Java\\
  Experience required &  Basic unit testing knowledge\\
 \hline
  \multicolumn{2}{|l|}{Input and Output of the tool} \\
  \hline
 Input & Bytecode of the target class and dependencies \\
\hline
Output&  JUnit test cases (version 3 or 4)\\
 
  \hline
  \multicolumn{2}{|l|}{Operation} \\
  \hline
  Interaction &  Through the command line\\
  User guidance &  manual verification of assertions for functional faults\\
  Source of information &  http://www.evosuite.org \\
  Maturity&  Mature research prototype, under development\\
  Technology behind the tool & Search-based testing / whole test suite generation\\
\hline
  \multicolumn{2}{|l|}{Obtaining the tool and information} \\
  \hline
License & GNU General Public License V3\\
Cost & Open source\\
Support & None \\
\hline
\hline
  \multicolumn{2}{|l|}{Does there exist empirical evidence about} \\
  \hline
  Effectiveness and Scalability & See~\cite{GoA_TSE12,FrA12b}. \\
%Completeness & \\
%Effectiveness & \\
%Efficiency & \\
%Defect types & \\
%Scalability & \\
%Comprehensibility & \\
%Learnability & \\
%Subjective satisfaction & \\
%Other & \\
\hline
\end{tabular}\vspace{-1em}
\end{table}



%------------------------------------------------------------------------- 
\subsection{Whole Test Suite Generation}

\EVOSUITE automatically generates JUnit test cases for a given
class. It requires only the bytecode of the class under test and its
dependencies as input. \EVOSUITE is based on search-based testing, and
uses a Genetic Algorithm (GA) to evolve a population of candidate test
suites with respect to a choice of code coverage criteria. 

This \emph{whole test suite generation} approach~\cite{GoA_TSE12} is a
key novelty of \EVOSUITE compared to other tools, and represents an
effective counter-measure to the problem of infeasible coverage
goals. When targeting individual goals one at a time, any resources
spent on an infeasible goal are per definition wasted, whereas the
search in \EVOSUITE is not adversely affected by the number of
infeasible goals~\cite{GoA_TSE12}. Our past experiments have shown
that this approach leads to significantly higher coverage than
targeting individual goals.


The search population in \EVOSUITE's GA is initialized with small
random test suites, which are successively evolved using crossover and
mutation. The number of tests and their length is variable, such that
the evolution will automatically lead to a suitable size of test suite
for the criterion at hand. This variability in length requires
bloat-control techniques to counter the problem of population
bloat~\cite{GoA11}. \EVOSUITE incorporates seeding
strategies~\cite{FrA12a} that boost coverage, even in the case of string
dependencies.

The default coverage criterion used by \EVOSUITE is branch coverage,
but there is also rudimentary support for dataflow and mutation
testing, and other coverage criteria could be integrated by encoding
them as fitness functions.

Before presenting test cases to the user, \EVOSUITE applies a range of
post-processing steps. Test cases are minimized, constants are
inlined, individual values can be minimized, and assertions can be
added to the test cases.


\subsection{Efficient Assertion Generation}

A key challenge in automated white-box testing is given by the human
oracle problem: Unless a test case reveals a generic fault such as an
undeclared exception, a tester manually needs to assess the test
outcome to decide whether a fault has been found. In unit testing of
object-oriented code, the oracle problem amounts to adding test
assertions to the unit tests. Because any given JUnit test case offers
a potentially large choice of assertions, \EVOSUITE determines which
of all the possible assertions for a given test case are good at
detecting faults. This is based on mutation
analysis~\cite{10.1109/TSE.2011.93}: \EVOSUITE first determines which
assertions can reveal mutations of the bytecode, and then uses a
heuristic to calculate a minimal set of assertions to detect all
mutants that the test can reveal. However, these assertions reflect
the currently implemented behaviour. This means that they can
immediately be used for regression testing, but to determine whether
there is a fault in the current version of the CUT the developer needs
to inspect and verify each of these assertions.

\subsection{Safe Test Execution}

To evaluate the fitness of a test suite, the GA in \EVOSUITE executes
all tests using instrumentation that collects the necessary data. The
test execution may have undesired side-effects, for example if the
class under test or the sequence of calls \EVOSUITE generated to
satisfy the dependencies access the filesystem. For example, when
running experiments on the 100 randomly selected projects of the \CS
corpus of classes~\cite{FrA12b} we observed creation of files with
random filenames and even deletion of entire directories. To prevent
such undesired actions, \EVOSUITE uses a custom security manager to
restrict test execution to a sandbox environment. Furthermore, to
restrict execution of GUI related code that may cause windows and
other GUI elements showing up during the search, \EVOSUITE is run in
\emph{headless} mode, such that no GUI elements will be shown.



%------------------------------------------------------------------------- 
\section{Configuration for the Competition Entry}

\EVOSUITE supports several coverage criteria, and many other
configuration options. Most of these configuration options are set to
reasonable defaults based on our studies on parameter
tuning~\cite{ArF11}, and we argue that in most cases a user should not
be required to change low-level parameters that would require an
understanding of the underlying techniques. However, it is reasonable
to assume that a user will know how long he or she is prepared to wait
for the results, and which test criterion the generated test cases
should satisfy. As branch coverage may be a weak criterion, in
particular if classes consist of many small methods with trivial
control flow, we chose \emph{weak mutation testing} as target
criterion. \EVOSUITE uses bytecode instrumentation to create a
meta-mutant for the class under test, and can then activate individual
mutants using a parameter. A mutant is weakly killed if it leads to an
immediate state change. Furthermore, we arbitrarily chose three
minutes as timeout for the search. This is based on our past
experience, where 10 minutes for a class in all but very complex
examples is more than enough time, whereas two minutes for non-trivial
classes with many mutants may easily be insufficient time. Given more
than three minutes would likely have resulted in higher coverage.

Considering that the score calculation in the SBST competition does
not directly include the test suite size or length (only in terms of
execution time), we deactivated the test minimization in \EVOSUITE, as
it will take significantly more time to minimize a test suite than can
be gained during execution. Furthermore, for the same reason we
deactivated assertion filtering, such that the resulting test cases
include all possible assertions.

%------------------------------------------------------------------------- 
\section{Benchmark results}

\begin{table*}[t]
  \centering
  \caption{\label{table:results}Detailed results of \EVOSUITE on the SBST benchmark classes.}
  \scriptsize
  \begin{tabular}{l rrrrrr} \toprule
Class & Generation Time & Execution Time  & Tests & Line Coverage & Branch
Coverage & Mutation Score \\ 
%Class & \multicolumn{2}{c}{ Time} & Tests & Line Coverage & Branch
%Coverage & Mutation Score \\ 
%& Generation & Execution & & & & \\
\midrule

\input{results.tex}
\midrule
Average & 186.3 & 0.05 & 9.06 & 0.61 & 0.58 & 0.13\\
\bottomrule
  \end{tabular}
\end{table*}

The results of \EVOSUITE on the benchmark classes are listed in
Table~\ref{table:results}. On average, \EVOSUITE achieved 61.4\% line
coverage, 57.6\% branch coverage\footnote{Using Cobertura's definition
  of branch coverage, which only counts conditional statements, not
  edges in the CFG.}, and 13.3\% mutation score. On average, \EVOSUITE
produced 9 tests per class, and it took an average of 186 per class to
do so (with \EVOSUITE configured to 3 minutes per class).

While the results on code coverage are in line with our expectations
from past experiments (e.g.,~\cite{FrA12b}), the mutation scores are
surprisingly low. A closer inspection of this unexpected result
revealed several issues in assertion generation, which are well known
in principle. The common problem is these cases is that the assertions
produced by \EVOSUITE do not hold upon test re-execution, and tests
with failing assertions are excluded from mutation analysis.

\subsection{Low Mutation Scores}

The first issue becomes apparent when considering the overall low
mutation scores on Joda Time classes, which are contrary to previous
results (e.g., \cite{10.1109/TSE.2011.93}). One reason for this is
that assertions in Joda Time tend to reflect the time during test
generation. For example, an instance of a time object based on the
current system time will include this time in its \<toString>
representation, and any successive test runs will fail, unless they
happen to be executed at the same time. \EVOSUITE in theory overcomes
this issue by instrumenting the bytecode such that all calls to
\<System.currentTimeMillis> and related methods are replaced with
custom calls that allow for deterministic test execution. However, to
enable this during JUnit test execution requires bytecode
instrumentation also at runtime. As this was not supported by the SBST
contest infrastructure, we deactivated this feature in \EVOSUITE.

The second issue we observed is related to static initializers, and is
an issue that is long known in test
generation~\cite{Csallner2004}. To make sure that test cases
are independent, all static initializers would need to be reset before
every single test execution. As this poses a significant overhead,
\EVOSUITE creates executable copies of the static initializer for each
class, removing assignments of \<final> fields. However, we
deactivated this feature in \EVOSUITE for the competition for
performance reasons, which possibly led to higher coverage, but
apparently to lower mutation scores.

\subsection{Classes with Low Coverage}

Besides the generally low mutation scores, we see nine classes on
which \EVOSUITE achieved 0\% coverage in
Table~\ref{table:results}. The classes {\it XlsSheetIterator} and {\it
  XlsxSheetIterator} both take a {\it URL} as input, which \EVOSUITE
produced using calls like {\it
  ClassLoader.getSystemResource("")}. However, the resulting URL
encodes the current directory during test generation and results in
assertions like
\begin{lstlisting}
assertEquals("/home/evosuite/", uRL0.getPath());
\end{lstlisting}
These assertions fail when executed during analysis in a different
directory, and consequently all tests for these classes fail even
before an instance of the target class has been produced, thus leading
to 0\% coverage. This problem would not have occurred if we had not
deactivated assertion minimization -- the problematic assertions are
unrelated to the class under test, and would have immediately been removed in normal operation.

The classes {\it net.sourceforge.barbecue.Barcode} and {\it
  LinearBarcode} are both GUI components extending {\it
  java.awt.Component} and cannot be initialised in \EVOSUITE in
headless mode and with activated sandbox.

{\it org.apache.commons.lang3.BooleanUtils} revealed a bug in
\EVOSUITE related to multi-dimensional arrays, which unfortunately led
to \EVOSUITE crashing on this class in all runs, even though the class
itself would be easily covered by \EVOSUITE. Similarly, the problem on
{\it org.joda.time.DurationField} is related to a bug in \EVOSUITE in
how it handles test generation for abstract classes.

{\it org.joda.time.field.MillisDurationField} is a tricky case: The
class has only a private constructor and thus cannot be constructed by
\EVOSUITE directly. There is one public static instance of the class,
but it is declared as its supertype:
\begin{lstlisting}
public static final DurationField INSTANCE = new MillisDurationField();
\end{lstlisting}
If \EVOSUITE would be left running long enough, then eventually it
would also try and assign this {\it INSTANCE} object, discovering that
it actually is a {\it MillisDurationField} instance. However, this did
not happen in the three minutes given for the competition.

Finally, the classes {\it BuddhistChronology}, {\it
  GregorianChronology}, and {\it DateTimeFormatterBuilder} are working
fine in our own experiments, so the reason for the 0\% coverage in the
competition is currently not clear to us; possibly this is related to
compile errors or failures in the produced JUnit tests. A further
possible contributing factor is that tests requiring the \EVOSUITE
security manager (e.g., when trying to access a file), then the
resulting JUnit test case spawns a new thread to execute the code
using the \EVOSUITE security manager. As this construct is not
supported by Javalanche, we automatically removed all such tests, thus
potentially reducing the coverage.

We also note that {\it org.joda.time.Chronology} achieves low coverage
(only 10.5\% line coverage). This is an interesting case, as much of
this class is contained in methods tagged as deprecated. By default,
\EVOSUITE does not attempt to cover deprecated code, although
deprecated code seems to be considered for coverage and mutation
analysis. However, \EVOSUITE can be configured to also cover
deprecated code.


%------------------------------------------------------------------------- 
\section{Conclusions}

The road to practically usable unit test generators is long,
and we are by far not there yet. The SBST competition has provided an
invaluable incentive to work on the robustness of \EVOSUITE, which in
writing research papers is usually not rewarded. The participation in
this competition has brought \EVOSUITE a big step closer to being
useful in practice, and it has helped us to identify areas where
future work is necessary to improve \EVOSUITE further.

To learn more about \EVOSUITE, visit our Web site:
\begin{center}
%\url{http://evosuite.org/}
\texttt{http://www.evosuite.org}
\end{center}


%------------------------------------------------------------------------- 
\noindent
\textbf{Acknowledgments.}  This project has been funded a Google
Focused Research Award on ``Test Amplification''. Andrea Arcuri is
funded by the Norwegian Research Council.



%------------------------------------------------------------------------- 
%\def\IEEEbibitemsep{5pt plus 1pt}
\def\IEEEbibitemsep{6pt}

\bibliographystyle{IEEEtranS}
\bibliography{../papers}

\end{document}

